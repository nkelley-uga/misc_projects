{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraping\n",
    "\n",
    "A brief guide to collecting and storing tweets.\n",
    "\n",
    "*NOTE:* Twitter data is **big data**. Since this is targeted at an audience using run-of-the-mill laptops, scope will be narrow. Bear in mind that changing a few parameters (ex. removing limits and start date) could be dangerous to your storage space.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Reference**\n",
    "\n",
    "Twitter Rate Limits: https://developer.twitter.com/en/docs/basics/rate-limiting\n",
    "\n",
    "GoT3: https://github.com/Mottl/GetOldTweets3\n",
    "\n",
    "tweepy: http://docs.tweepy.org/en/latest/\n",
    "\n",
    "---\n",
    "\n",
    "**Required Installs:**\n",
    "\n",
    "```\n",
    "!pip install GetOldTweets3\n",
    "\n",
    "!pip install tweepy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Overview:**\n",
    "\n",
    "Following is a notebook to walk through two libraries for retrieving tweets - GetOldTweets3 and tweepy - from project idea to a starting point.\n",
    "\n",
    "* GoT3 takes a very minimal amount of time to start using, and offers more historical data than tweepy, but lacks streaming capability.\n",
    "\n",
    "* Tweepy's main benefit is that it offers the ability to gather streaming data, however, it requires Twitter app authorization.\n",
    "\n",
    "---\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: GetOldTweets3\n",
    "\n",
    "For projects or models requiring a dataset beyond the scope of tweepy, use got.\n",
    "\n",
    "Minimal everything is required, even code.\n",
    "\n",
    "Tweets can be searched by keyword or username, parameters include: minimum date, maximum date, maximum number to scrape, and emoji format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Exactly. Don't worry about it. Even if the kids want to for a little skate in the park, what's the harm?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic query\n",
    "\n",
    "basic_query = got.manager.TweetCriteria().setQuerySearch('coronavirus')\\\n",
    "                                         .setMaxTweets(1)\n",
    "\n",
    "tweet = got.manager.TweetManager.getTweets(basic_query)\n",
    "\n",
    "tweet[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pior que o covid19 e o bovid17 só a minha vizinha falando que nem a Ivana de Avenida Brasil com o momolado dela, cara eles tem qse 50 anos\n",
      "\n",
      "El Año del Coronavirus - XXXVII día de Confinamiento - Foto y frase: ©José María Navarro Cayuela #YoMeQuedoEnCasa #QuedateEnCasa #VenceremosAlVirus\n",
      "\n",
      "Secondo me a fine anno prenderanno pure il premio produttività, che sarà ricalcolato tenendo conto delle difficoltà legata al #coronavirus. Scommettiamo o pensi che vinco facile?\n",
      "\n",
      "#IranRegimeChange The regime's own officials are awakening Rouhani of the big mistake he's making You can support rights of +80M #Iranians, at risk of #COVID19 death, by appealing to @UNHumanRights for firm observation of decent #coronavirus measures to be taken by Rouhani. \n",
      "\n",
      "Americans at World Health Organization transmitted real-time information about coronavirus to Trump administration \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tweaking time and max tweets\n",
    "\n",
    "earlier_tweets = got.manager.TweetCriteria().setQuerySearch('coronavirus')\\\n",
    "                                            .setSince('2020-01-15')\\\n",
    "                                            .setMaxTweets(5)\n",
    "\n",
    "more_tweets = got.manager.TweetManager.getTweets(earlier_tweets)\n",
    "\n",
    "for tweet in more_tweets:\n",
    "    print(tweet.text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-pastable function for username scrape bounded by time (no inherent max)\n",
    "\n",
    "def tweet_to_df(user, start, stop):\n",
    "    '''\n",
    "    Function to scrape tweets from the GetOldTweets3 API into a dataframe.\n",
    "    \n",
    "    Refer to [https://pypi.org/project/GetOldTweets3/] for additional info and tweet fields.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user: the username of target tweeter - could be changed easily to text scrape\n",
    "    start: inclusive date to start scraping\n",
    "    stop: exclusive date to stop scraping\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>tweet_to_df('@McDonalds', '2020-04-01', '2020-04-03')\n",
    "    returns a dataframe of size () of tweets by @McDonalds for the first half of April, 2020\n",
    "    '''\n",
    "    tweetCriteria = got.manager.TweetCriteria()\\\n",
    "                                .setUsername(user)\\\n",
    "                                .setSince(start)\\\n",
    "                                .setUntil(stop)\n",
    "    \n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    text_tweets = [[tweet.date, \n",
    "                    tweet.text,\n",
    "                    tweet.favorites, \n",
    "                    tweet.retweets]\n",
    "                   for tweet in tweets]\n",
    "    \n",
    "    return pd.DataFrame(text_tweets,\n",
    "                        columns=['datetime', 'text', 'favorites', 'retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.81 s, sys: 176 ms, total: 4.99 s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(856, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# mo-tweets mo-time\n",
    "\n",
    "mac_tweets = tweet_to_df('@McDonalds', '2020-04-01', '2020-04-03')\n",
    "\n",
    "mac_tweets.shape  # rows, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: tweepy\n",
    "\n",
    "Cute name. You can push the skill-curve as high as you want on this one. For now, let's just hit the ground.\n",
    "\n",
    "To get to this point:\n",
    "\n",
    "1. [Jump through all the hoops, make a developer account](https://developer.twitter.com/en/apply-for-access)\n",
    "2. [More hoops, get an app started](https://developer.twitter.com/en/apps)\n",
    "    * No need to do anything beyond generating your app token and secret!\n",
    "3. Open your app tab, click on \"Keys and Tokens\"\n",
    "4. Create a text/json file to store all 4: API key, API secret key, Access token, Access token secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json works too, this is for anyone who has simply copy-pasted into 4 lines...\n",
    "\n",
    "# each line should look like...  thing: crazylongpassword\n",
    "info = open('secret.txt').read()\n",
    "info = info.split('\\n') # break it up by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access_token: ********** \n",
      "\n",
      "secret: ********** \n",
      "\n",
      "api_key: ********** \n",
      "\n",
      "api_secret_key: ********** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we have\n",
    "\n",
    "for i in info:\n",
    "    print(f\"{i.split(':')[0]}: {'*'*10} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which allows us to access the Twitter API\n",
    "\n",
    "access_token = info[0].split(': ')[1] # first line of secret.txt\n",
    "secret = info[1].split(': ')[1] # second line\n",
    "\n",
    "api_key = info[2].split(': ')[1]\n",
    "api_secret = info[3].split(': ')[1]\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grab your mental pickaxe!\n"
     ]
    }
   ],
   "source": [
    "# quick check for sanity\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Grab your mental pickaxe!')\n",
    "except:\n",
    "    print(\"I can't believe you've done this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elemental, limited tweet stream\n",
    "\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.limit = 5\n",
    "    \n",
    "    def on_status(self, status): \n",
    "        if self.counter < self.limit:\n",
    "            print(status.text + '\\n')\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @thiruja: குவைத் நாட்டில் கண்டறியப்பட்ட 1658 கொரொனோ நோயாளிகளில் 924 பேர் இந்தியாவை சேர்ந்தவர்கள். எனினும் இந்தியர்களால் கொரொனோ பரவுகிறது…\n",
      "\n",
      "RT @CoronaviridaeRu: Неофициально (по данным оппозиции) количество смертей вызванных коронавирусом в Иране более 31,500.\n",
      "https://t.co/cIQt7…\n",
      "\n",
      "No es solo nuestro gobierno el que ha podido hacer algo mal con el CoronaVirus, es el mundo entero\n",
      "\n",
      "COVID-19 Datasets Now Available on Databricks: How the Data Community Can Help \n",
      "#bigdata #covid19… https://t.co/ABsQEtl1Xs\n",
      "\n",
      "RT @DVATW: “Injustice”? Have you SEEN the shocking non conformance to social distancing that some BAME ppl in your city have engaged in? I…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup and look for keywords\n",
    "\n",
    "stream_listener = StreamListener()\n",
    "stream = tweepy.Stream(auth=api.auth, listener=stream_listener)\n",
    "\n",
    "stream.filter(track=['covid', 'covid-19', 'coronavirus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
